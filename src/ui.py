import os
import streamlit as st
from dotenv import load_dotenv
from google import genai
from google.genai import types
import time

# Load environment variables
load_dotenv()
gemini_client = genai.Client(api_key=os.getenv("GEMINI_API_KEY"))

# Medical chatbot system prompt
MEDICAL_SYSTEM_PROMPT = """
You are LyLy, a friendly and empathetic school psychological counseling assistant developed by students from Th·ªëng Nh·∫•t Secondary and High School.

Follow these principles:
    1. Cung c·∫•p th√¥ng tin v√† l·ªùi khuy√™n v·ªÅ t√¢m l√Ω h·ªçc ƒë∆∞·ªùng m·ªôt c√°ch ch√≠nh x√°c, d·ª±a tr√™n c∆° s·ªü khoa h·ªçc v√† ngu·ªìn t√†i li·ªáu ƒë√°ng tin c·∫≠y.
    2. Lu√¥n gi·ªØ gi·ªçng ƒëi·ªáu th√¢n thi·ªán, l·∫Øng nghe v√† ƒë·ªìng c·∫£m trong m·ªçi ph·∫£n h·ªìi.
    3. V·ªõi c√°c v·∫•n ƒë·ªÅ t√¢m l√Ω ph·ª©c t·∫°p ho·∫∑c kh·∫©n c·∫•p, h√£y lu√¥n nh·∫Øc nh·ªü ng∆∞·ªùi d√πng t√¨m ƒë·∫øn chuy√™n gia t√¢m l√Ω ho·∫∑c ng∆∞·ªùi l·ªõn ƒë√°ng tin c·∫≠y ƒë·ªÉ ƒë∆∞·ª£c h·ªó tr·ª£ tr·ª±c ti·∫øp.
    4. Kh√¥ng ch·∫©n ƒëo√°n hay ƒë∆∞a ra k·∫ø ho·∫°ch tr·ªã li·ªáu c√° nh√¢n h√≥a.
    5. Lu√¥n l√†m r√µ r·∫±ng th√¥ng tin ch·ªâ mang t√≠nh ch·∫•t tham kh·∫£o chung, kh√¥ng thay th·∫ø cho t∆∞ v·∫•n chuy√™n m√¥n.
    6. Minh b·∫°ch v·ªÅ gi·ªõi h·∫°n c·ªßa m·ªôt tr·ª£ l√Ω AI trong lƒ©nh v·ª±c t√¢m l√Ω h·ªçc ƒë∆∞·ªùng.
    7. T·∫≠p trung v√†o vi·ªác gi√°o d·ª•c v·ªÅ s·ª©c kh·ªèe t√¢m th·∫ßn, k·ªπ nƒÉng s·ªëng, ·ª©ng ph√≥ c·∫£m x√∫c, v√† x√¢y d·ª±ng m·ªëi quan h·ªá t√≠ch c·ª±c.
    8. Khi n√≥i ƒë·∫øn v·∫•n ƒë·ªÅ li√™n quan ƒë·∫øn c·∫£m x√∫c, stress, ho·∫∑c √°p l·ª±c h·ªçc t·∫≠p, ch·ªâ cung c·∫•p th√¥ng tin v√† h∆∞·ªõng d·∫´n chung.
    9. Trong tr∆∞·ªùng h·ª£p kh·∫©n c·∫•p (v√≠ d·ª•: c√≥ d·∫•u hi·ªáu nguy c∆° t·ª± l√†m h·∫°i b·∫£n th√¢n ho·∫∑c ng∆∞·ªùi kh√°c), h√£y lu√¥n khuy√™n ng∆∞·ªùi d√πng li√™n h·ªá ngay v·ªõi th·∫ßy c√¥, cha m·∫π, ho·∫∑c c√°c d·ªãch v·ª• h·ªó tr·ª£ kh·∫©n c·∫•p.
    10. T√¥n tr·ªçng s·ª± ri√™ng t∆∞ v√† lu√¥n th·ªÉ hi·ªán s·ª± t√¥n tr·ªçng v·ªõi t·∫•t c·∫£ v·∫•n ƒë·ªÅ li√™n quan ƒë·∫øn t√¢m l√Ω h·ªçc sinh.
    11. T·∫•t c·∫£ ph·∫£n h·ªìi ƒë·ªÅu b·∫±ng ti·∫øng Vi·ªát.
    12. Trong tr∆∞·ªùng h·ª£p ng∆∞·ªùi d√πng h·ªèi c√°c c√¢u h·ªèi kh√¥ng c√≥ li√™n quan g√¨ v·ªÅ y t·∫ø h√£y t·ª´ ch·ªëi tr·∫£ l·ªùi theo h∆∞·ªõng: t√¥i l√† m·ªôt tr·ª£ l√Ω ƒë∆∞·ª£c ph√°t tri·ªÉn ƒë·ªÉ tr·∫£ l·ªùi c√°c th√¥ng tin v·ªÅ y t·∫ø. T√¥i kh√¥ng th·ªÉ cung c·∫•p b·∫•t k·ª≥ th√¥ng tin n√†o li√™n quan t·ªõi c√°c lƒ©nh v·ª±c kh√°c ngo√†i chuy√™n m√¥n.
"""

# Thi·∫øt l·∫≠p ch·∫ø ƒë·ªô m·∫∑c ƒë·ªãnh l√† Light Mode
# ƒê·∫∑t bi·∫øn m√¥i tr∆∞·ªùng tr∆∞·ªõc khi set_page_config
os.environ['STREAMLIT_THEME'] = 'light'

# Set page configuration
st.set_page_config(
    page_title="LyLy - Tr·ª£ l√Ω t√¢m l√Ω h·ªçc ƒë∆∞·ªùng",
    page_icon="üíº",
    layout="wide",
    initial_sidebar_state="expanded",
    menu_items={
        'Get Help': 'https://www.facebook.com/thongnhathighschool',
        'Report a bug': "mailto:contact@thongnhathighschool.edu.vn",
        'About': "LyLy l√† tr·ª£ l√Ω t√¢m l√Ω h·ªçc ƒë∆∞·ªùng ƒë∆∞·ª£c ph√°t tri·ªÉn b·ªüi h·ªçc sinh l·ªõp 3A tr∆∞·ªùng THTHCS Th·ªëng Nh·∫•t"
    }
)

# Thi·∫øt l·∫≠p Light Mode m·∫∑c ƒë·ªãnh th√¥ng qua CSS
st.markdown("""
<script>
    // ƒê·∫∑t theme m·∫∑c ƒë·ªãnh l√† light mode
    localStorage.setItem('color-theme', 'light');

    // ƒê·∫£m b·∫£o giao di·ªán hi·ªÉn th·ªã ·ªü light mode
    document.documentElement.classList.remove('dark');
    document.documentElement.classList.add('light');
</script>
""", unsafe_allow_html=True)

# Apply custom CSS for better styling
st.markdown("""
<style>
    /* Light mode styling */
    .light {
        --background-color: #ffffff;
        --text-color: #333333;
        --highlight-color: #6a98fb;
        --user-message-bg: #e6f2ff;
        --assistant-message-bg: #f0f8ff;
        --border-color: #dedede;
    }

    /* Overrides for light mode */
    .stApp {
        background-color: #f8f9fa !important;
    }

    .main-header {
        font-size: 2.5rem;
        color: #1E88E5;
        text-align: center;
        margin-bottom: 1rem;
        font-weight: 600;
    }

    .sub-header {
        color: #0D47A1;
        font-weight: 600;
    }

    .chat-container {
        border-radius: 10px;
        padding: 20px;
        margin-bottom: 20px;
        background-color: white;
        box-shadow: 0 1px 3px rgba(0,0,0,0.1);
    }

    .disclaimer {
        font-size: 0.9rem;
        color: #D32F2F;
        margin-top: 10px;
    }

    .sidebar-content {
        padding: 15px;
        background-color: #ffffff;
        border-radius: 8px;
        box-shadow: 0 1px 2px rgba(0,0,0,0.05);
    }

    .chat-message-user {
        background-color: #E3F2FD;
        border-radius: 15px 15px 15px 5px;
        padding: 12px 18px;
        margin-bottom: 15px;
        border-left: 5px solid #1E88E5;
        box-shadow: 0 1px 2px rgba(0,0,0,0.05);
    }

    .chat-message-assistant {
        background-color: #F1F8E9;
        border-radius: 15px 15px 5px 15px;
        padding: 12px 18px;
        margin-bottom: 15px;
        border-left: 5px solid #689F38;
        box-shadow: 0 1px 2px rgba(0,0,0,0.05);
    }

    .stTextInput>div>div>input {
        border-radius: 20px;
        padding: 10px 15px;
        border: 1px solid #dde1e5;
    }

    .stButton>button {
        border-radius: 20px;
        background-color: #1E88E5;
        color: white;
        font-weight: 500;
        padding: 8px 16px;
        transition: all 0.2s ease;
    }

    .stButton>button:hover {
        background-color: #1565C0;
        box-shadow: 0 2px 5px rgba(0,0,0,0.2);
    }

    .info-box {
        background-color: #F1F8E9;
        border-radius: 10px;
        padding: 15px;
        margin: 10px 0;
        border-left: 5px solid #689F38;
    }

    .emergency-box {
        background-color: #FFEBEE;
        border-radius: 10px;
        padding: 15px;
        margin: 10px 0;
        border-left: 5px solid #D32F2F;
    }

    footer {
        text-align: center;
        margin-top: 30px;
        font-size: 0.8rem;
        color: #757575;
        padding: 15px;
        background-color: #f8f9fa;
        border-top: 1px solid #e9ecef;
        border-radius: 0 0 8px 8px;
    }

    /* N√∫t thay ƒë·ªïi theme */
    .theme-toggle {
        display: flex;
        justify-content: center;
        margin: 10px 0;
    }

    /* Thanh tr∆∞·ª£t theme */
    .theme-slider {
        padding: 5px;
        background-color: #f0f2f5;
        border-radius: 20px;
        width: 100%;
        display: flex;
        justify-content: space-between;
    }
</style>
""", unsafe_allow_html=True)

# Chat history stored in session state
if "messages" not in st.session_state:
    st.session_state.messages = []
    # Add system message (not visible to user)
    st.session_state.messages.append({"role": "system", "content": MEDICAL_SYSTEM_PROMPT})

# Configuration in session state
if "config" not in st.session_state:
    st.session_state.config = {
        "temperature": 0.3,
        "language": "Vietnamese",
        "model": "gemini-2.0-flash",
        "theme": "light"  # Th√™m c√†i ƒë·∫∑t theme m·∫∑c ƒë·ªãnh
    }

def stream_gemini_response(prompt):
    """Stream response from Gemini model"""
    # Include chat history in the prompt for context
    chat_history = ""
    if len(st.session_state.messages) > 1:  # Skip first system message
        for message in st.session_state.messages[1:]:
            role = "User: " if message["role"] == "user" else "Assistant: "
            chat_history += f"{role}{message['content']}\n\n"

    # Complete prompt with chat history
    full_prompt = f"Previous conversation:\n{chat_history}\nUser: {prompt}\n\nAssistant: "

    try:
        response = gemini_client.models.generate_content_stream(
            model=st.session_state.config["model"],
            config=types.GenerateContentConfig(
                system_instruction=MEDICAL_SYSTEM_PROMPT,
                temperature=st.session_state.config["temperature"],
                top_p=0.95,
                top_k=40,
                max_output_tokens=1024,
            ),
            contents=full_prompt
        )

        return response
    except Exception as e:
        st.error(f"Error generating response: {e}")
        return None

# Main layout
col1, col2, col3 = st.columns([1, 3, 1])
with col2:
    st.markdown("<h1 class='main-header'>üë©‚Äçüíº Tr·ª£ l√Ω LyLy</h1>", unsafe_allow_html=True)
    st.markdown("<p style='text-align: center; font-size: 1.2rem;'>Tr·ª£ l√Ω t∆∞ v·∫•n t√¢m l√Ω h·ªçc ƒë∆∞·ªùng ƒë∆∞·ª£c t·∫°o b·ªüi l·ªõp 3A tr∆∞·ªùng THTHCS Th·ªëng Nh·∫•t</p>", unsafe_allow_html=True)

# Sidebar for configurations and information
with st.sidebar:
    st.markdown("<div class='sidebar-content'>", unsafe_allow_html=True)

    # Logo and title
    st.image("https://cdn-icons-png.flaticon.com/512/4320/4320371.png", width=100)
    st.markdown("<h2 class='sub-header'>C√†i ƒë·∫∑t LyLy</h2>", unsafe_allow_html=True)

    # Theme selection
    st.markdown("<h3>üé® Giao di·ªán</h3>", unsafe_allow_html=True)
    theme_options = ["Light", "Dark"]
    selected_theme = st.radio(
        "Ch·ªçn giao di·ªán:",
        options=theme_options,
        index=theme_options.index("Light"),  # Light l√† m·∫∑c ƒë·ªãnh
        key="theme_select",
        horizontal=True
    )
    st.session_state.config["theme"] = selected_theme

    # Hi·ªÉn th·ªã ƒëo·∫°n m√£ JavaScript ƒë·ªÉ thay ƒë·ªïi theme
    if selected_theme == "Dark":
        st.markdown("""
        <script>
            localStorage.setItem('color-theme', 'dark');
            document.documentElement.classList.remove('light');
            document.documentElement.classList.add('dark');
        </script>
        """, unsafe_allow_html=True)
    else:
        st.markdown("""
        <script>
            localStorage.setItem('color-theme', 'light');
            document.documentElement.classList.remove('dark');
            document.documentElement.classList.add('light');
        </script>
        """, unsafe_allow_html=True)

    # Configuration options
    st.markdown("<h3>‚öôÔ∏è Tu·ª≥ ch·ªânh m√¥ h√¨nh AI</h3>", unsafe_allow_html=True)

    model_options = ["gemini-2.0-flash"]
    selected_model = st.selectbox(
        "AI Model:",
        options=model_options,
        index=model_options.index(st.session_state.config["model"]),
        key="model_select"
    )
    st.session_state.config["model"] = selected_model

    temperature = st.slider(
        "ƒê·ªô s√°ng t·∫°o:",
        min_value=0.0,
        max_value=1.0,
        value=st.session_state.config["temperature"],
        step=0.1,
        help="Th·∫•p = Tr·∫£ l·ªùi ch·∫∑t ch·∫Ω, Cao = Tr·∫£ l·ªùi s√°ng t·∫°o h∆°n"
    )
    st.session_state.config["temperature"] = temperature

    language_options = ["Vietnamese"]
    selected_language = st.selectbox(
        "Ng√¥n ng·ªØ tr·∫£ l·ªùi:",
        options=language_options,
        index=language_options.index(st.session_state.config["language"]),
        key="language_select"
    )
    st.session_state.config["language"] = selected_language

    st.divider()

    # About and Disclaimers
    st.markdown("<h3>‚ÑπÔ∏è Gi·ªõi thi·ªáu v·ªÅ LyLy</h3>", unsafe_allow_html=True)
    st.markdown("""
    <div class='info-box'>
    LyLy l√† tr·ª£ l√Ω t∆∞ v·∫•n t√¢m l√Ω h·ªçc ƒë∆∞·ªùng ƒë∆∞·ª£c ph√°t tri·ªÉn b·ªüi nh√≥m h·ªçc sinh tr∆∞·ªùng THTHCS Th·ªëng Nh·∫•t, nh·∫±m h·ªó tr·ª£ c√°c b·∫°n h·ªçc sinh gi·∫£i quy·∫øt c√°c v·∫•n ƒë·ªÅ t√¢m l√Ω ph·ªï bi·∫øn.
    </div>
    """, unsafe_allow_html=True)

    st.markdown("<h3>‚ö†Ô∏è L∆∞u √Ω quan tr·ªçng</h3>", unsafe_allow_html=True)
    st.markdown("""
    <div class='emergency-box'>
    <strong>Mi·ªÖn Tr·ª´ Tr√°ch Nhi·ªám</strong><br>
    LyLy hi·ªán t·∫°i ƒëang trong giai ƒëo·∫°n ph√°t tri·ªÉn. C√°c l·ªùi khuy√™n t·ª´ LyLy ch·ªâ mang t√≠nh ch·∫•t tham kh·∫£o.
    </div>
    <div class='disclaimer'>
    ‚Ä¢ ƒê·ªëi v·ªõi c√°c v·∫•n ƒë·ªÅ t√¢m l√Ω nghi√™m tr·ªçng, vui l√≤ng li√™n h·ªá v·ªõi chuy√™n gia t√¢m l√Ω ho·∫∑c th·∫ßy c√¥ gi√°o.<br>
    ‚Ä¢ Kh√¥ng s·ª≠ d·ª•ng LyLy cho c√°c t√¨nh hu·ªëng kh·∫©n c·∫•p.<br>
    ‚Ä¢ Th√¥ng tin ƒë∆∞·ª£c cung c·∫•p kh√¥ng thay th·∫ø cho t∆∞ v·∫•n chuy√™n m√¥n.
    </div>
    """, unsafe_allow_html=True)

    # Clear chat button with confirmation
    st.divider()
    if st.button("üóëÔ∏è Xo√° Cu·ªôc H·ªôi Tho·∫°i", use_container_width=True):
        st.session_state.messages = [{"role": "system", "content": MEDICAL_SYSTEM_PROMPT}]
        st.rerun()

    st.markdown("</div>", unsafe_allow_html=True)

# Main chat interface
chat_container = st.container()

with chat_container:
    st.markdown("<div class='chat-container'>", unsafe_allow_html=True)

    # Display welcome message if no messages
    if len(st.session_state.messages) <= 1:
        st.markdown("""
        <div class='chat-message-assistant'>
        <p><strong>LyLy:</strong> Xin ch√†o! M√¨nh l√† LyLy, tr·ª£ l√Ω t∆∞ v·∫•n t√¢m l√Ω h·ªçc ƒë∆∞·ªùng ƒë∆∞·ª£c ph√°t tri·ªÉn b·ªüi nh√≥m h·ªçc sinh tr∆∞·ªùng THTHCS Th·ªëng Nh·∫•t. M√¨nh c√≥ th·ªÉ gi√∫p b·∫°n gi·∫£i ƒë√°p c√°c th·∫Øc m·∫Øc v·ªÅ s·ª©c kh·ªèe t√¢m l√Ω, c√°c v·∫•n ƒë·ªÅ h·ªçc t·∫≠p ho·∫∑c c√°c m·ªëi quan h·ªá ·ªü tr∆∞·ªùng h·ªçc. B·∫°n c√≥ ƒëi·ªÅu g√¨ mu·ªën chia s·∫ª v·ªõi m√¨nh kh√¥ng?</p>
        </div>
        """, unsafe_allow_html=True)

    # Display chat messages
    for message in st.session_state.messages:
        if message["role"] != "system":  # Don't show system messages
            message_class = "chat-message-user" if message["role"] == "user" else "chat-message-assistant"
            display_name = "B·∫°n" if message["role"] == "user" else "LyLy"

            st.markdown(f"""
            <div class='{message_class}'>
            <p><strong>{display_name}:</strong> {message["content"]}</p>
            </div>
            """, unsafe_allow_html=True)

    st.markdown("</div>", unsafe_allow_html=True)

# User input area
user_input = st.chat_input("H√£y chia s·∫ª c√¢u h·ªèi ho·∫∑c v·∫•n ƒë·ªÅ c·ªßa b·∫°n...")

if user_input:
    # Add user message to chat history
    st.session_state.messages.append({"role": "user", "content": user_input})

    # Create a placeholder for the assistant's message
    message_placeholder = st.empty()

    # Display typing animation
    typing_text = "LyLy ƒëang suy nghƒ© c√¢u tr·∫£ l·ªùi..."
    with st.chat_message("assistant"):
        message_placeholder.markdown(f"<div class='chat-message-assistant'><p>{typing_text}</p></div>", unsafe_allow_html=True)

    # Get streamed response
    response_stream = stream_gemini_response(user_input)
    full_response = ""

    if response_stream:
        # Replace typing animation with actual response
        with st.chat_message("assistant"):
            response_container = st.empty()

            # Process the streaming response
            for chunk in response_stream:
                if hasattr(chunk, 'text') and chunk.text:
                    full_response += chunk.text
                    response_container.markdown(f"<div class='chat-message-assistant'><p><strong>LyLy:</strong> {full_response}‚ñå</p></div>", unsafe_allow_html=True)
                    time.sleep(0.01)  # Small delay for smoother appearance

            # Final response without cursor
            response_container.markdown(f"<div class='chat-message-assistant'><p><strong>LyLy:</strong> {full_response}</p></div>", unsafe_allow_html=True)

            # Add assistant response to chat history
            st.session_state.messages.append({"role": "assistant", "content": full_response})
    else:
        with st.chat_message("assistant"):
            st.markdown(f"""
            <div class='chat-message-assistant'>
            <p><strong>LyLy:</strong> Xin l·ªói, m√¨nh kh√¥ng th·ªÉ t·∫°o ph·∫£n h·ªìi l√∫c n√†y. Vui l√≤ng th·ª≠ l·∫°i sau nh√©.</p>
            </div>
            """, unsafe_allow_html=True)

    # Rerun to update the UI
    st.rerun()

# Footer
st.markdown("""
<footer>
    <p>LyLy v1.0 | ƒê∆∞·ª£c ph√°t tri·ªÉn b·ªüi nh√≥m h·ªçc sinh tr∆∞·ªùng THTHCS Th·ªëng Nh·∫•t | ¬© 2025</p>
    <p>Lu√¥n s·∫µn s√†ng l·∫Øng nghe v√† h·ªó tr·ª£ c√°c b·∫°n h·ªçc sinh.</p>
</footer>
""", unsafe_allow_html=True)
import os
import streamlit as st
from dotenv import load_dotenv
from google import genai
from google.genai import types
import time

# Load environment variables
load_dotenv()
gemini_client = genai.Client(api_key=os.getenv("GEMINI_API_KEY"))

# Medical chatbot system prompt
MEDICAL_SYSTEM_PROMPT = """
You are LyLy, a friendly and empathetic school psychological counseling assistant developed by students from Th·ªëng Nh·∫•t Secondary and High School.

Follow these principles:
    1. Cung c·∫•p th√¥ng tin v√† l·ªùi khuy√™n v·ªÅ t√¢m l√Ω h·ªçc ƒë∆∞·ªùng m·ªôt c√°ch ch√≠nh x√°c, d·ª±a tr√™n c∆° s·ªü khoa h·ªçc v√† ngu·ªìn t√†i li·ªáu ƒë√°ng tin c·∫≠y.
    2. Lu√¥n gi·ªØ gi·ªçng ƒëi·ªáu th√¢n thi·ªán, l·∫Øng nghe v√† ƒë·ªìng c·∫£m trong m·ªçi ph·∫£n h·ªìi.
    3. V·ªõi c√°c v·∫•n ƒë·ªÅ t√¢m l√Ω ph·ª©c t·∫°p ho·∫∑c kh·∫©n c·∫•p, h√£y lu√¥n nh·∫Øc nh·ªü ng∆∞·ªùi d√πng t√¨m ƒë·∫øn chuy√™n gia t√¢m l√Ω ho·∫∑c ng∆∞·ªùi l·ªõn ƒë√°ng tin c·∫≠y ƒë·ªÉ ƒë∆∞·ª£c h·ªó tr·ª£ tr·ª±c ti·∫øp.
    4. Kh√¥ng ch·∫©n ƒëo√°n hay ƒë∆∞a ra k·∫ø ho·∫°ch tr·ªã li·ªáu c√° nh√¢n h√≥a.
    5. Lu√¥n l√†m r√µ r·∫±ng th√¥ng tin ch·ªâ mang t√≠nh ch·∫•t tham kh·∫£o chung, kh√¥ng thay th·∫ø cho t∆∞ v·∫•n chuy√™n m√¥n.
    6. Minh b·∫°ch v·ªÅ gi·ªõi h·∫°n c·ªßa m·ªôt tr·ª£ l√Ω AI trong lƒ©nh v·ª±c t√¢m l√Ω h·ªçc ƒë∆∞·ªùng.
    7. T·∫≠p trung v√†o vi·ªác gi√°o d·ª•c v·ªÅ s·ª©c kh·ªèe t√¢m th·∫ßn, k·ªπ nƒÉng s·ªëng, ·ª©ng ph√≥ c·∫£m x√∫c, v√† x√¢y d·ª±ng m·ªëi quan h·ªá t√≠ch c·ª±c.
    8. Khi n√≥i ƒë·∫øn v·∫•n ƒë·ªÅ li√™n quan ƒë·∫øn c·∫£m x√∫c, stress, ho·∫∑c √°p l·ª±c h·ªçc t·∫≠p, ch·ªâ cung c·∫•p th√¥ng tin v√† h∆∞·ªõng d·∫´n chung.
    9. Trong tr∆∞·ªùng h·ª£p kh·∫©n c·∫•p (v√≠ d·ª•: c√≥ d·∫•u hi·ªáu nguy c∆° t·ª± l√†m h·∫°i b·∫£n th√¢n ho·∫∑c ng∆∞·ªùi kh√°c), h√£y lu√¥n khuy√™n ng∆∞·ªùi d√πng li√™n h·ªá ngay v·ªõi th·∫ßy c√¥, cha m·∫π, ho·∫∑c c√°c d·ªãch v·ª• h·ªó tr·ª£ kh·∫©n c·∫•p.
    10. T√¥n tr·ªçng s·ª± ri√™ng t∆∞ v√† lu√¥n th·ªÉ hi·ªán s·ª± t√¥n tr·ªçng v·ªõi t·∫•t c·∫£ v·∫•n ƒë·ªÅ li√™n quan ƒë·∫øn t√¢m l√Ω h·ªçc sinh.
    11. T·∫•t c·∫£ ph·∫£n h·ªìi ƒë·ªÅu b·∫±ng ti·∫øng Vi·ªát.
    12. Trong tr∆∞·ªùng h·ª£p ng∆∞·ªùi d√πng h·ªèi c√°c c√¢u h·ªèi kh√¥ng c√≥ li√™n quan g√¨ v·ªÅ y t·∫ø h√£y t·ª´ ch·ªëi tr·∫£ l·ªùi theo h∆∞·ªõng: t√¥i l√† m·ªôt tr·ª£ l√Ω ƒë∆∞·ª£c ph√°t tri·ªÉn ƒë·ªÉ tr·∫£ l·ªùi c√°c th√¥ng tin v·ªÅ y t·∫ø. T√¥i kh√¥ng th·ªÉ cung c·∫•p b·∫•t k·ª≥ th√¥ng tin n√†o li√™n quan t·ªõi c√°c lƒ©nh v·ª±c kh√°c ngo√†i chuy√™n m√¥n.
"""

os.environ['STREAMLIT_THEME'] = 'light'

# Set page configuration
st.set_page_config(
    page_title="MediAssist - Medical Chatbot",
    page_icon="ü©∫",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Apply custom CSS for better styling
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1E88E5;
        text-align: center;
        margin-bottom: 1rem;
        font-weight: 600;
    }
    .sub-header {
        color: #0D47A1;
        font-weight: 600;
    }
    .chat-container {
        border-radius: 10px;
        padding: 20px;
        margin-bottom: 20px;
    }
    .disclaimer {
        font-size: 0.9rem;
        color: #D32F2F;
        margin-top: 10px;
    }
    .sidebar-content {
        padding: 15px;
    }
    .chat-message-user {
        background-color: #E3F2FD;
        border-radius: 10px;
        padding: 10px 15px;
        margin-bottom: 10px;
        border-left: 5px solid #1E88E5;
    }
    .chat-message-assistant {
        background-color: #F1F8E9;
        border-radius: 10px;
        padding: 10px 15px;
        margin-bottom: 10px;
        border-left: 5px solid #689F38;
    }
    .stTextInput>div>div>input {
        border-radius: 20px;
        padding: 10px 15px;
    }
    .stButton>button {
        border-radius: 20px;
        background-color: #1E88E5;
        color: white;
        font-weight: 500;
    }
    .info-box {
        background-color: #F1F8E9;
        border-radius: 10px;
        padding: 15px;
        margin: 10px 0;
        border-left: 5px solid #689F38;
    }
    .emergency-box {
        background-color: #FFEBEE;
        border-radius: 10px;
        padding: 15px;
        margin: 10px 0;
        border-left: 5px solid #D32F2F;
    }
    footer {
        text-align: center;
        margin-top: 30px;
        font-size: 0.8rem;
        color: #757575;
    }
</style>
""", unsafe_allow_html=True)

# Chat history stored in session state
if "messages" not in st.session_state:
    st.session_state.messages = []
    # Add system message (not visible to user)
    st.session_state.messages.append({"role": "system", "content": MEDICAL_SYSTEM_PROMPT})

# Configuration in session state
if "config" not in st.session_state:
    st.session_state.config = {
        "temperature": 0.3,
        "language": "Vietnamese",
        "model": "gemini-2.0-flash"
    }

def stream_gemini_response(prompt):
    """Stream response from Gemini model"""
    # Include chat history in the prompt for context
    chat_history = ""
    if len(st.session_state.messages) > 1:  # Skip first system message
        for message in st.session_state.messages[1:]:
            role = "User: " if message["role"] == "user" else "Assistant: "
            chat_history += f"{role}{message['content']}\n\n"

    # Complete prompt with chat history
    full_prompt = f"Previous conversation:\n{chat_history}\nUser: {prompt}\n\nAssistant: "

    try:
        response = gemini_client.models.generate_content_stream(
            model=st.session_state.config["model"],
            config=types.GenerateContentConfig(
                system_instruction=MEDICAL_SYSTEM_PROMPT,
                temperature=st.session_state.config["temperature"],
                top_p=0.95,
                top_k=40,
                max_output_tokens=1024,
            ),
            contents=full_prompt
        )

        return response
    except Exception as e:
        st.error(f"Error generating response: {e}")
        return None

# Main layout
col1, col2, col3 = st.columns([1, 3, 1])
with col2:
    st.markdown("<h1 class='main-header'>ü©∫ LyLy Assistant</h1>", unsafe_allow_html=True)
    st.markdown("<p style='text-align: center; font-size: 1.2rem;'>Tr·ª£ l√Ω t∆∞ v·∫•n t√¢m l√Ω LyLy</p>", unsafe_allow_html=True)

# Sidebar for configurations and information
with st.sidebar:
    st.markdown("<div class='sidebar-content'>", unsafe_allow_html=True)

    # Logo and title
    st.image("https://cdn-icons-png.flaticon.com/512/4320/4320371.png", width=100)
    st.markdown("<h2 class='sub-header'>LyLy Settings</h2>", unsafe_allow_html=True)

    # Configuration options
    st.markdown("<h3>‚öôÔ∏è Tu·ª≥ ch·ªânh m√¥ h√¨nh AI</h3>", unsafe_allow_html=True)

    model_options = ["gemini-2.0-flash"]
    selected_model = st.selectbox(
        "AI Model:",
        options=model_options,
        index=model_options.index(st.session_state.config["model"]),
        key="model_select"
    )
    st.session_state.config["model"] = selected_model

    temperature = st.slider(
        "Response Style:",
        min_value=0.0,
        max_value=1.0,
        value=st.session_state.config["temperature"],
        step=0.1,
        help="Lower = More factual, Higher = More creative"
    )
    st.session_state.config["temperature"] = temperature

    language_options = ["Vietnamese", "English", "Bilingual (Viet+Eng)"]
    selected_language = st.selectbox(
        "Ch·ªçn ng√¥n ng·ªØ tr·∫£ l·ªùi:",
        options=language_options,
        index=language_options.index(st.session_state.config["language"]),
        key="language_select"
    )
    st.session_state.config["language"] = selected_language

    st.divider()

    # About and Disclaimers
    st.markdown("<h3>‚ÑπÔ∏è Gi·ªõi thi·ªáu v·ªÅ LyLy</h3>", unsafe_allow_html=True)
    st.markdown("""
    <div class='info-box'>
    LyLy l√† tr·ª£ l√Ω th√¥ng tin y t·∫ø s·ª≠ d·ª•ng AI ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ cung c·∫•p th√¥ng tin v√† h∆∞·ªõng d·∫´n v·ªÅ s·ª©c kh·ªèe n√≥i chung.
    </div>
    """, unsafe_allow_html=True)

    st.markdown("<h3>‚ö†Ô∏è L∆∞u √Ω</h3>", unsafe_allow_html=True)
    st.markdown("""
    <div class='emergency-box'>
    <strong>Mi·ªÖn Tr·ª´ Tr√°ch Nhi·ªám</strong><br>
    LyLy hi·ªán t·∫°i ƒëang trong giai ƒëo·∫°n ph√°t tri·ªÉn c√°c l·ªùi khuy√™n t·ª´ LyLy ch·ªâ mang t√≠nh ch·∫•t tham kh·∫£o.
    </div>

    """, unsafe_allow_html=True)

    # Clear chat button with confirmation
    st.divider()
    if st.button("üóëÔ∏è Xo√° Cu·ªôc H·ªôi Tho·∫°i", use_container_width=True):
        st.session_state.messages = [{"role": "system", "content": MEDICAL_SYSTEM_PROMPT}]
        st.rerun()

    st.markdown("</div>", unsafe_allow_html=True)

# Main chat interface
chat_container = st.container()

with chat_container:
    st.markdown("<div class='chat-container'>", unsafe_allow_html=True)

    # Display welcome message if no messages
    if len(st.session_state.messages) <= 1:
        st.markdown("""
        <div class='chat-message-assistant'>
        <p><strong>MediAssist:</strong> Xin ch√†o! T√¥i l√† LyLy , tr·ª£ l√Ω y t·∫ø AI. T√¥i c√≥ th·ªÉ cung c·∫•p th√¥ng tin y t·∫ø chung v√† h∆∞·ªõng d·∫´n s·ª©c kh·ªèe. B·∫°n c√≥ c√¢u h·ªèi g√¨ v·ªÅ s·ª©c kh·ªèe kh√¥ng?</p>
        </div>
        """, unsafe_allow_html=True)

    # Display chat messages
    for message in st.session_state.messages:
        if message["role"] != "system":  # Don't show system messages
            message_class = "chat-message-user" if message["role"] == "user" else "chat-message-assistant"
            display_name = "You" if message["role"] == "user" else "MediAssist"

            st.markdown(f"""
            <div class='{message_class}'>
            <p><strong>{display_name}:</strong> {message["content"]}</p>
            </div>
            """, unsafe_allow_html=True)

    st.markdown("</div>", unsafe_allow_html=True)

# User input area
user_input = st.chat_input("H√£y nh·∫≠p c√¢u h·ªèi c≈©a b·∫°n...")

if user_input:
    # Add user message to chat history
    st.session_state.messages.append({"role": "user", "content": user_input})

    # Create a placeholder for the assistant's message
    message_placeholder = st.empty()

    # Display typing animation
    typing_text = "Vui l√≤ng ch·ªù m·ªôt t√≠ nh√©. T√¥i s·∫Ω cung c·∫•p c√¢u tr·∫£ l·ªùi cho b·∫°n..."
    with st.chat_message("assistant"):
        message_placeholder.markdown(f"<div class='chat-message-assistant'><p>{typing_text}</p></div>", unsafe_allow_html=True)

    # Get streamed response
    response_stream = stream_gemini_response(user_input)
    full_response = ""

    if response_stream:
        # Replace typing animation with actual response
        with st.chat_message("assistant"):
            response_container = st.empty()

            # Process the streaming response
            for chunk in response_stream:
                if hasattr(chunk, 'text') and chunk.text:
                    full_response += chunk.text
                    response_container.markdown(f"<div class='chat-message-assistant'><p><strong>MediAssist:</strong> {full_response}‚ñå</p></div>", unsafe_allow_html=True)
                    time.sleep(0.01)  # Small delay for smoother appearance

            # Final response without cursor
            response_container.markdown(f"<div class='chat-message-assistant'><p><strong>MediAssist:</strong> {full_response}</p></div>", unsafe_allow_html=True)

            # Add assistant response to chat history
            st.session_state.messages.append({"role": "assistant", "content": full_response})
    else:
        with st.chat_message("assistant"):
            st.markdown(f"""
            <div class='chat-message-assistant'>
            <p><strong>MediAssist:</strong> Xin l·ªói, t√¥i kh√¥ng th·ªÉ t·∫°o ph·∫£n h·ªìi. Vui l√≤ng th·ª≠ l·∫°i sau.</p>
            <p><em>(I'm sorry, I couldn't generate a response. Please try again.)</em></p>
            </div>
            """, unsafe_allow_html=True)

    # Rerun to update the UI
    st.rerun()

# Footer
st.markdown("""
<footer>
    <p>LyLy v1.0 | ƒê∆∞·ª£c h·ªó tr·ª£ b·ªüi nh√≥m h·ªçc sinh tr∆∞·ªùng THTHCS Th·ªëng Nh·∫•t | ¬© 2025</p>
    <p>Lu√¥n lu√¥n ƒë∆∞a ra c√°c l·ªùi khuy√™n h·ªØu √≠ch cho c√°c em h·ªçc sinh.</p>
</footer>
""", unsafe_allow_html=True)